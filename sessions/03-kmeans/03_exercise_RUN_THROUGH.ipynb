{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-exercise-RUN THROUGH",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVsPkPvGVEpq"
      },
      "source": [
        "# installs\n",
        "\n",
        "# colab\n",
        "# ! pip install scikit-plot\n",
        "\n",
        "# local/server\n",
        "# pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9Q1EGnHVLHJ"
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from scipy.spatial.distance import pdist\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "import scikitplot as skplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdmDDM4aVxYS"
      },
      "source": [
        "# COLAB - auth big query\n",
        "\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "# print('Authenticated')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIFx5cirV9IC"
      },
      "source": [
        "# get the data\n",
        "SQL = \"SELECT * from `questrom.datasets.spotify_2018`\"\n",
        "PROJECT = \"questrom\"\n",
        "\n",
        "\n",
        "spotify = pd.read_gbq(SQL, PROJECT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWQ5QcMyWO2Q"
      },
      "source": [
        "# the shape\n",
        "spotify.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CQSz8k2WSmQ"
      },
      "source": [
        "# quick review\n",
        "spotify.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc-VTSYZXYWM"
      },
      "source": [
        "# info\n",
        "spotify.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FmUBGq_XaYq"
      },
      "source": [
        "# summary\n",
        "spotify.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5IUXB__XoRi"
      },
      "source": [
        "# time, mode, key\n",
        "# docs\n",
        "# https://developer.spotify.com/documentation/web-api/reference/#object-audiofeaturesobject\n",
        "COLS = ['time_signature', 'mode', 'key', 'name', 'artists']\n",
        "\n",
        "X = spotify.drop(columns=COLS)\n",
        "X.index = X.id\n",
        "\n",
        "del X['id']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62TNBPWgYZq-"
      },
      "source": [
        "# quick preview\n",
        "X.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOho9EeQYaYn"
      },
      "source": [
        "# scale, because clearly these are not on the same scale, and I want to ensure each variable has equal weight\n",
        "sc = StandardScaler()\n",
        "xs = sc.fit_transform(X)\n",
        "X = pd.DataFrame(xs, index=X.index, columns=X.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7lBqrK0ZH0q"
      },
      "source": [
        "# confirm\n",
        "X.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C4_iuAQZRrK"
      },
      "source": [
        "# hclust\n",
        "METHODS = ['single', 'complete', 'average', 'ward']\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "\n",
        "# loop and build our plot\n",
        "for i, m in enumerate(METHODS):\n",
        "  plt.subplot(1, 4, i+1)\n",
        "  plt.title(m)\n",
        "  dendrogram(linkage(X.values, method=m),\n",
        "             labels = X.index,\n",
        "             leaf_rotation=90,\n",
        "             leaf_font_size=10)\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7_AwpcKaXSc"
      },
      "source": [
        "# average or ward look like appear to have favorable properties to me\n",
        "# we can think of genres as a macro or micro level\n",
        "# for example: https://www.musicgenreslist.com/\n",
        "# dataset appears to be a list of top 100 songs\n",
        "# I am going to use average because I want to test if the top songs span some generes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB3eYseccTf7"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "avg = linkage(X.values, method=\"average\")\n",
        "dendrogram(avg,\n",
        "          labels = X.index,\n",
        "          leaf_rotation=90,\n",
        "          leaf_font_size=10, color_threshold=4)\n",
        "\n",
        "plt.axhline(y=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA-0cM1RccSu"
      },
      "source": [
        "# the clusters\n",
        "hc_labs = fcluster(avg, 4, criterion=\"distance\")\n",
        "\n",
        "# the metrics\n",
        "hc_silo = silhouette_score(X, hc_labs)\n",
        "hc_ssamps = silhouette_samples(X, hc_labs)\n",
        "np.unique(hc_labs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rGY-HNKdZjM"
      },
      "source": [
        "# Kmeans\n",
        "KS = range(2, 30)\n",
        "\n",
        "# storage\n",
        "inertia = []\n",
        "silo = []\n",
        "\n",
        "for k in KS:\n",
        "  km = KMeans(k)\n",
        "  km.fit(X)\n",
        "  labs = km.predict(X)\n",
        "  inertia.append(km.inertia_)\n",
        "  silo.append(silhouette_score(X, labs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRDl4HQqfsRJ"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Inertia\")\n",
        "sns.lineplot(KS, inertia)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Silohouette Score\")\n",
        "sns.lineplot(KS, silo)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgtHBSoYgF3O"
      },
      "source": [
        "for i, s in enumerate(silo[:10]):\n",
        "  print(i+2,s) # +2 to align num clusters with value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEFoQR28gqr1"
      },
      "source": [
        "# 9 looks like a good number, we get improvement in silo score and approx. \n",
        "# where the elbow could be viewed for interita\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVAxK9lWhLSo"
      },
      "source": [
        "# get the model\n",
        "k9 = KMeans(9)\n",
        "k9_labs = k9.fit_predict(X)\n",
        "\n",
        "# metrics\n",
        "k9_silo = silhouette_score(X, k9_labs)\n",
        "k9_ssamps = silhouette_samples(X, k9_labs)\n",
        "np.unique(k9_labs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6XlvUEPhc6t"
      },
      "source": [
        "# lets compare via silo\n",
        "\n",
        "skplot.metrics.plot_silhouette(X, hc_labs, title=\"HClust\", figsize=(15,5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYPSKy13h3p8"
      },
      "source": [
        "skplot.metrics.plot_silhouette(X, k9_labs, title=\"KMeans - 9\", figsize=(15,5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtFm_8CIkixp"
      },
      "source": [
        "# I like the Kmeans fit.  There are a few negative values, which suggests fit could be off, \n",
        "# but some of the clusters look pretty good."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8THV-zevlQBw"
      },
      "source": [
        "# lets profile the songs\n",
        "spotify['k9_labs'] = k9_labs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoAf3lJNlWdG"
      },
      "source": [
        "# profile\n",
        "profile = spotify.groupby('k9_labs').mean()\n",
        "profile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqDlKX9klarN"
      },
      "source": [
        "# heatmap\n",
        "sc = StandardScaler()\n",
        "profile_scaled = sc.fit_transform(profile)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "pal = sns.color_palette(\"vlag\", as_cmap=True)\n",
        "sns.heatmap(profile_scaled, center=0, cmap=pal, xticklabels=profile.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCMa8ITenp_Y"
      },
      "source": [
        "# counts by cluster\n",
        "spotify.k9_labs.value_counts(sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0bKrMXDl2vT"
      },
      "source": [
        "# OBSERVATIONS:\n",
        "#1. profile 0 = apperas to be longer songs\n",
        "#2. profile 1 = higher likelihood of a live song\n",
        "#3. profile 5 = only 1 song, and its larger on instrumentalness\n",
        "#4. profile 4 = appears to a reprsentation of \"average\" songs\n",
        "#5. profile 8 = the largest cluster, tends to be high on positivity measure, but less on tempo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H8aing-pBeb"
      },
      "source": [
        "# CONSIDERATIONS\n",
        "# - Look at DBSCAN\n",
        "# - explore both distance metrics (euclidean used) and different linkage approaches\n",
        "# - I was ok with 9 clusters because this task was to think about genre proxies.  \n",
        "#   In some cases, large number of clusters are not actionable for a firm because the management is too \n",
        "#   resource intensives.  Because we are trying to dervice genres, volume is not an issue\n",
        "# - consider the features themselves.  Perhaps we don't need to use them all in the case some are correlated.\n",
        "# - Dive deeper into profiling.  Look at the songs within the clusters to validate as best as you can.\n",
        "# - Enrich the dataset by appending/annotating the true genre of each song. \n",
        "#   After clustering the data, profile by the true genres to get a sense of how the segments align."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}